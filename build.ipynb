{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.1.0-cp37-cp37m-macosx_10_11_x86_64.whl (120.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 120.8 MB 1.1 MB/s eta 0:00:01    |████████▎                       | 31.1 MB 156 kB/s eta 0:09:34\n",
      "\u001b[?25hCollecting protobuf>=3.8.0\n",
      "  Downloading protobuf-3.11.3-cp37-cp37m-macosx_10_9_x86_64.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 315 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /Users/akshaymattoo/opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.11.2)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.2.0-py3-none-any.whl (63 kB)\n",
      "\u001b[K     |████████████████████████████████| 63 kB 510 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
      "  Using cached tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448 kB)\n",
      "Collecting google-pasta>=0.1.6\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 552 kB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /Users/akshaymattoo/opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.18.1)\n",
      "Collecting grpcio>=1.8.6\n",
      "  Downloading grpcio-1.28.1-cp37-cp37m-macosx_10_9_x86_64.whl (2.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.6 MB 744 kB/s eta 0:00:01\n",
      "\u001b[?25hProcessing /Users/akshaymattoo/Library/Caches/pip/wheels/7c/06/54/bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6/termcolor-1.1.0-cp37-none-any.whl\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /Users/akshaymattoo/opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (0.34.2)\n",
      "Collecting absl-py>=0.7.0\n",
      "  Using cached absl-py-0.9.0.tar.gz (104 kB)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in /Users/akshaymattoo/opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /Users/akshaymattoo/opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.4.1)\n",
      "Collecting gast==0.2.2\n",
      "  Using cached gast-0.2.2.tar.gz (10 kB)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /Users/akshaymattoo/opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.0.8)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/akshaymattoo/opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.14.0)\n",
      "Collecting tensorboard<2.2.0,>=2.1.0\n",
      "  Downloading tensorboard-2.1.1-py3-none-any.whl (3.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8 MB 800 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting astor>=0.6.0\n",
      "  Using cached astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: setuptools in /Users/akshaymattoo/opt/anaconda3/lib/python3.7/site-packages (from protobuf>=3.8.0->tensorflow) (46.0.0.post20200309)\n",
      "Requirement already satisfied: h5py in /Users/akshaymattoo/opt/anaconda3/lib/python3.7/site-packages (from keras-applications>=1.0.8->tensorflow) (2.10.0)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.1-py2.py3-none-any.whl (18 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.2.1-py2.py3-none-any.whl (88 kB)\n",
      "\u001b[K     |████████████████████████████████| 88 kB 898 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.13.1-py2.py3-none-any.whl (87 kB)\n",
      "\u001b[K     |████████████████████████████████| 87 kB 912 kB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: werkzeug>=0.11.15 in /Users/akshaymattoo/opt/anaconda3/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/akshaymattoo/opt/anaconda3/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (2.22.0)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.0.0-py3-none-any.whl (10 kB)\n",
      "Collecting rsa<4.1,>=3.1.4\n",
      "  Using cached rsa-4.0-py2.py3-none-any.whl (38 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/akshaymattoo/opt/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/akshaymattoo/opt/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/akshaymattoo/opt/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/akshaymattoo/opt/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2019.11.28)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "Collecting pyasn1>=0.1.3\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Building wheels for collected packages: absl-py, gast\n",
      "  Building wheel for absl-py (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for absl-py: filename=absl_py-0.9.0-py3-none-any.whl size=121931 sha256=aa34d069a917db8eb3540236080df4067c0124ba16730ce78f8719edd6e84560\n",
      "  Stored in directory: /Users/akshaymattoo/Library/Caches/pip/wheels/cc/af/1a/498a24d0730ef484019e007bb9e8cef3ac00311a672c049a3e\n",
      "  Building wheel for gast (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7539 sha256=8179d9bce1a577c3aa97f26082cf62f33001ed2f5b29a0534be70898bc7797a0\n",
      "  Stored in directory: /Users/akshaymattoo/Library/Caches/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
      "Successfully built absl-py gast\n",
      "Installing collected packages: protobuf, opt-einsum, tensorflow-estimator, google-pasta, grpcio, termcolor, absl-py, gast, cachetools, pyasn1, rsa, pyasn1-modules, google-auth, oauthlib, requests-oauthlib, google-auth-oauthlib, markdown, tensorboard, astor, tensorflow\n",
      "Successfully installed absl-py-0.9.0 astor-0.8.1 cachetools-4.0.0 gast-0.2.2 google-auth-1.13.1 google-auth-oauthlib-0.4.1 google-pasta-0.2.0 grpcio-1.28.1 markdown-3.2.1 oauthlib-3.1.0 opt-einsum-3.2.0 protobuf-3.11.3 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rsa-4.0 tensorboard-2.1.1 tensorflow-2.1.0 tensorflow-estimator-2.1.0 termcolor-1.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y0jiFo1BBH2u"
   },
   "source": [
    "#### Build a vocabulary of the most commonly occurring words in the caption text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vBB9Ll2HA39Q"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "import collections\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Input, Dense, Dropout, Embedding, LSTM\n",
    "from keras.layers.merge import add\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "86Tme1m1DRWh"
   },
   "outputs": [],
   "source": [
    "# Read the file tokens_clean.txt and store the cleaned captions in a dictionary\n",
    "content = None\n",
    "\n",
    "with open (\"data/textFiles/tokens_clean.txt\", 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "json_acceptable_string = content.replace(\"'\", \"\\\"\")\n",
    "content = json.loads(json_acceptable_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "oagj043m0RF7",
    "outputId": "6760df47-68e2-402d-dfa3-4911cc5b8466"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print(type(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "hu5zr0PF0Tmf",
    "outputId": "393d645e-e70a-4af2-9649-13c3571bcd45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size = 8441\n"
     ]
    }
   ],
   "source": [
    "# Build the vocabulary\n",
    "\n",
    "vocab = set()\n",
    "for key in content.keys():\n",
    "    for sentence in content[key]:\n",
    "        vocab.update(sentence.split())\n",
    "\n",
    "print(\"Vocab size = %d\" %len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "mJj07-us1nHO",
    "outputId": "4c749983-b1ea-4910-cee5-1fb12ee7ec4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Words = 437466\n"
     ]
    }
   ],
   "source": [
    "total_words = []\n",
    "\n",
    "for key in content.keys():\n",
    "    for caption in content[key]:\n",
    "        for i in caption.split():\n",
    "            total_words.append(i)\n",
    "\n",
    "print(\"Total Words = %d\" %len(total_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "_iSvMykj2U5p",
    "outputId": "addc3d96-72ff-4ebe-cad4-f63f45341f48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8441\n"
     ]
    }
   ],
   "source": [
    "# Compute the frequency of occurrence of each word\n",
    "\n",
    "counter = collections.Counter(total_words)\n",
    "freq_cnt = dict(counter)\n",
    "\n",
    "print(len(freq_cnt.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "RS6z377m2lba",
    "outputId": "d10b1121-c9e7-401d-c08f-9cf0c5d55a73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2644\n"
     ]
    }
   ],
   "source": [
    "# Sort the dictionary according to frequency of occurrence\n",
    "\n",
    "sorted_freq_cnt = sorted(freq_cnt.items(), reverse=True, key=lambda x:x[1])\n",
    "\n",
    "#Filter off those words which occur less than the threshold\n",
    "threshold = 5\n",
    "sorted_freq_cnt = [x for x in sorted_freq_cnt if x[1]>threshold]\n",
    "total_words = [x[0] for x in sorted_freq_cnt]\n",
    "\n",
    "print(len(total_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YMR7OwXUJ-Sc"
   },
   "source": [
    "#### Prepare train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RlYAnylP4M-7"
   },
   "outputs": [],
   "source": [
    "# Read training and testing image names\n",
    "\n",
    "train_file_data = \"\"\n",
    "test_file_data = \"\"\n",
    "\n",
    "with open (\"data/textFiles/trainImages.txt\", 'r') as file:\n",
    "    train_file_data = file.read()\n",
    "\n",
    "with open (\"data/textFiles/testImages.txt\", 'r') as file:\n",
    "    test_file_data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ym0EQ-dcHlll"
   },
   "outputs": [],
   "source": [
    "# Obtain a list of train and test images\n",
    "train_data = [img_file_name for img_file_name in train_file_data.split(\"\\n\")[:-1]]\n",
    "test_data = [img_file_name for img_file_name in test_file_data.split(\"\\n\")[:-1]]\n",
    "\n",
    "# Obtain image ID from image file name\n",
    "train_data = [image.split(\".\")[0] for image in train_data]\n",
    "test_data = [image.split(\".\")[0] for image in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "zSmjcfwQIn1i",
    "outputId": "1ea4876a-9e51-427d-d044-7ad3d9fa219a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2513260012_03d33305cf',\n",
       " '2903617548_d3e38d7f88',\n",
       " '3338291921_fe7ae0c8f8',\n",
       " '488416045_1c6d903fe0',\n",
       " '2644326817_8f45080b87']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e_LFtjHyI8KL"
   },
   "outputs": [],
   "source": [
    "# For each imageID in train_data, store its captions in a dictionary \n",
    "\n",
    "train_content = {}\n",
    "\n",
    "for imageID in train_data:\n",
    "    train_content[imageID] = []\n",
    "    for caption in content[imageID]:\n",
    "        # Add a start sequence token in the beginning and an end sequence token at the end\n",
    "        cap_to_append = \"startseq \" + caption + \" endseq\"\n",
    "        train_content[imageID].append(cap_to_append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "eKIPDcpMJOIN",
    "outputId": "a710287b-e9f9-4060-a57c-e66053c80476"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['startseq a child playing on a rope net  endseq',\n",
       " 'startseq a little girl climbing on red roping  endseq',\n",
       " 'startseq a little girl in pink climbs a rope bridge at the park  endseq',\n",
       " 'startseq a small child grips onto the red ropes at the playground  endseq',\n",
       " 'startseq the small child climbs on a red ropes on a playground  endseq']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_content['1007320043_627395c3d8']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E6RqXZjqXYNw"
   },
   "source": [
    "### Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PeeOPvEeXeWX"
   },
   "source": [
    "#### Extract features from Image using a ResNet50 Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521
    },
    "colab_type": "code",
    "id": "kuGU6xSCJzOr",
    "outputId": "5719bfdc-df50-41c7-c850-1306c8971151"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
      "102858752/102853048 [==============================] - 482s 5us/step\n"
     ]
    }
   ],
   "source": [
    "model = ResNet50(weights = 'imagenet', input_shape = (224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "EeRHZAI3Xdw2",
    "outputId": "2f59def3-e74d-4f03-ae2e-8b48bfdea32b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fc1000 (Dense)                  (None, 1000)         2049000     avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 25,636,712\n",
      "Trainable params: 25,583,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b9BF10ORX-DL"
   },
   "outputs": [],
   "source": [
    "model_new = Model (model.input, model.layers[-2].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LrFFLIgIYUpZ"
   },
   "outputs": [],
   "source": [
    "def preprocess_image (img):\n",
    "    img = image.load_img(img, target_size=(224, 224))\n",
    "    img = image.img_to_array(img)\n",
    "\n",
    "    # Convert 3D tensor to a 4D tendor\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "\n",
    "    #Normalize image accoring to ResNet50 requirement\n",
    "    img = preprocess_input(img)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "zP5iYv38Yv3T",
    "outputId": "c7ba2986-2c66-47e3-c2d0-b7a96be8cafd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = preprocess_image(\"data/Images/1000268201_693b08cb0e.jpg\")\n",
    "plt.imshow(img[0])\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cGajBDSiZP7O"
   },
   "outputs": [],
   "source": [
    "# A wrapper function, which inputs an image and returns its encoding (feature vector)\n",
    "def encode_image (img):\n",
    "    img = preprocess_image(img)\n",
    "    feature_vector = model_new.predict(img)\n",
    "\n",
    "    fature_vector = feature_vector.reshape((-1,))\n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "rJ5elpspf6sP",
    "outputId": "5101e229-a30e-465f-a65a-47fe61b4e69e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding in progress... STEP 0\n",
      "Encoding in progress... STEP 100\n",
      "Encoding in progress... STEP 200\n",
      "Encoding in progress... STEP 300\n",
      "Encoding in progress... STEP 400\n",
      "Encoding in progress... STEP 500\n",
      "Encoding in progress... STEP 600\n",
      "Encoding in progress... STEP 700\n",
      "Encoding in progress... STEP 800\n",
      "Encoding in progress... STEP 900\n",
      "Encoding in progress... STEP 1000\n",
      "Encoding in progress... STEP 1100\n",
      "Encoding in progress... STEP 1200\n",
      "Encoding in progress... STEP 1300\n",
      "Encoding in progress... STEP 1400\n",
      "Encoding in progress... STEP 1500\n",
      "Encoding in progress... STEP 1600\n",
      "Encoding in progress... STEP 1700\n",
      "Encoding in progress... STEP 1800\n",
      "Encoding in progress... STEP 1900\n",
      "Encoding in progress... STEP 2000\n",
      "Encoding in progress... STEP 2100\n",
      "Encoding in progress... STEP 2200\n",
      "Encoding in progress... STEP 2300\n",
      "Encoding in progress... STEP 2400\n",
      "Encoding in progress... STEP 2500\n",
      "Encoding in progress... STEP 2600\n",
      "Encoding in progress... STEP 2700\n",
      "Encoding in progress... STEP 2800\n",
      "Encoding in progress... STEP 2900\n",
      "Encoding in progress... STEP 3000\n",
      "Encoding in progress... STEP 3100\n",
      "Encoding in progress... STEP 3200\n",
      "Encoding in progress... STEP 3300\n",
      "Encoding in progress... STEP 3400\n",
      "Encoding in progress... STEP 3500\n",
      "Encoding in progress... STEP 3600\n",
      "Encoding in progress... STEP 3700\n",
      "Encoding in progress... STEP 3800\n",
      "Encoding in progress... STEP 3900\n",
      "Encoding in progress... STEP 4000\n",
      "Encoding in progress... STEP 4100\n",
      "Encoding in progress... STEP 4200\n",
      "Encoding in progress... STEP 4300\n",
      "Encoding in progress... STEP 4400\n",
      "Encoding in progress... STEP 4500\n",
      "Encoding in progress... STEP 4600\n",
      "Encoding in progress... STEP 4700\n",
      "Encoding in progress... STEP 4800\n",
      "Encoding in progress... STEP 4900\n",
      "Encoding in progress... STEP 5000\n",
      "Encoding in progress... STEP 5100\n",
      "Encoding in progress... STEP 5200\n",
      "Encoding in progress... STEP 5300\n",
      "Encoding in progress... STEP 5400\n",
      "Encoding in progress... STEP 5500\n",
      "Encoding in progress... STEP 5600\n",
      "Encoding in progress... STEP 5700\n",
      "Encoding in progress... STEP 5800\n",
      "Encoding in progress... STEP 5900\n",
      "Total time taken: 1019.5407402515411\n"
     ]
    }
   ],
   "source": [
    "train_encoding = {}\n",
    "# Create a dictionary of iamgeID and its feature vector\n",
    "\n",
    "start_time = time()\n",
    "for index, imageID in enumerate (train_data):\n",
    "    image_path = \"data/Images/\" + imageID + \".jpg\"\n",
    "    \n",
    "    train_encoding[imageID] = encode_image(image_path)\n",
    "\n",
    "    # Print progress\n",
    "    if index%100 == 0:\n",
    "        print(\"Encoding in progress... STEP\", index)\n",
    "\n",
    "end_time = time()\n",
    "print(\"Total time taken:\", end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "669aLGXrh6u4"
   },
   "outputs": [],
   "source": [
    "# Store the above computed features on the disk\n",
    "# Use pickle to dump the entire data\n",
    "\n",
    "with open(\"encoded_train_features.pkl\", \"wb\") as file:\n",
    "    # Pickle allows to store any object as a file on the disk\n",
    "    pickle.dump(train_encoding, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gczVyLkbjxOR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding in progress... STEP 0\n",
      "Encoding in progress... STEP 100\n",
      "Encoding in progress... STEP 200\n",
      "Encoding in progress... STEP 300\n",
      "Encoding in progress... STEP 400\n",
      "Encoding in progress... STEP 500\n",
      "Encoding in progress... STEP 600\n",
      "Encoding in progress... STEP 700\n",
      "Encoding in progress... STEP 800\n",
      "Encoding in progress... STEP 900\n",
      "Total time taken: 208.69454503059387\n"
     ]
    }
   ],
   "source": [
    "test_encoding = {}\n",
    "# Create a dictionary of iamgeID and its feature vector\n",
    "\n",
    "start_time = time()\n",
    "for index, imageID in enumerate (test_data):\n",
    "    image_path = \"data/Images/\" + imageID + \".jpg\"\n",
    "    \n",
    "    test_encoding[imageID] = encode_image(image_path)\n",
    "\n",
    "    # Print progress\n",
    "    if index%100 == 0:\n",
    "        print(\"Encoding in progress... STEP\", index)\n",
    "\n",
    "end_time = time()\n",
    "print(\"Total time taken:\", end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A4AUcLctlFoC"
   },
   "outputs": [],
   "source": [
    "with open(\"encoded_test_features.pkl\", \"wb\") as file:\n",
    "    # Pickle allows to store any object as a file on the disk\n",
    "    pickle.dump(test_encoding, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b69Erxn9jaNn"
   },
   "source": [
    "#### Pre-process the Captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UN3ixKADyKGV"
   },
   "outputs": [],
   "source": [
    "# Create the word-to-index and index-to-word mappings\n",
    "word_to_index = {}\n",
    "index_to_word = {}\n",
    "\n",
    "for i, word in enumerate(total_words):\n",
    "    word_to_index[word] = i+1\n",
    "    index_to_word[i+1] = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "EypUHPKBj2la",
    "outputId": "e44bc7bd-4f3a-4017-80a2-b67a743e96f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2644\n"
     ]
    }
   ],
   "source": [
    "print(len(index_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "q5mt8xUFj83Z",
    "outputId": "707a6ba5-4d21-48eb-e71e-5a7d505a5429"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(index_to_word[5])\n",
    "print(word_to_index['is'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TvDVpv7NkBg1"
   },
   "outputs": [],
   "source": [
    "# Add startseq and endseq also to the mappings\n",
    "index_to_word[2645] = 'startseq'\n",
    "word_to_index['startseq'] = 2645\n",
    "\n",
    "index_to_word[2646] = 'endseq'\n",
    "word_to_index['endseq'] = 2646\n",
    "\n",
    "vocab_size = len(word_to_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "g7Kb1N9Pkets",
    "outputId": "9c6490e2-e8a0-4848-f78e-4ced9ee3a7fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2647\n"
     ]
    }
   ],
   "source": [
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hutToQzWkoHK"
   },
   "outputs": [],
   "source": [
    "# Get the maximum length of a caption\n",
    "max_len = 0\n",
    "\n",
    "for cap_list in train_content.keys():\n",
    "    for caption in train_content[cap_list]:\n",
    "        max_len = max(max_len, len(caption.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "4j-XDU0UlATp",
    "outputId": "cd4b9b3f-c2d7-43f0-d3a8-ba258c118ca4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n"
     ]
    }
   ],
   "source": [
    "print(max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9DTgZ8qzC3ay"
   },
   "source": [
    "#### Create a Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aPPEZ_2ElCHl"
   },
   "outputs": [],
   "source": [
    "def data_generator (train_content, train_encoding, word_to_index, max_len, batch_size):\n",
    "    X1, X2, y = [], [], []\n",
    "\n",
    "    n = 0\n",
    "    while True:\n",
    "        for imageID, cap_list in train_content.items():\n",
    "            n += 1\n",
    "\n",
    "            image = encoding_train [imageID + \".jpg\"]\n",
    "\n",
    "            for caption in cap_list:\n",
    "                idx_seq = [word_to_index[word] for word in caption.split() if word in word_to_index]\n",
    "\n",
    "                for i in range (1, len(idx_seq)):\n",
    "                    xi = seq[0 : i] # The input sequence of words\n",
    "                    yi = seq[i] # The next word after the above sequence (this is expected to be predicted)\n",
    "\n",
    "                    # Add a padding of zeros ao lengths of input sequences become equal\n",
    "                    xi = pad_sequences([xi], maxlen=max_len, value=0, padding='0')[0] # Take the first row only, since this method inputs & returns a 2D array\n",
    "                    # Convert the expected word to One Hot vector notation\n",
    "                    yi = to_categorical([yi], num_classes=vocab_size)[0]\n",
    "\n",
    "                    X1.append(image)\n",
    "                    X2.append(xi)\n",
    "                    y.append(yi)\n",
    "\n",
    "                if n==batch_size:\n",
    "                   yield [[np.array(X1), np.array(X2)], np.array(y)]\n",
    "                   X1, X2, y = [], [], []\n",
    "                   n=0     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "65ZYQhU2F9gl"
   },
   "outputs": [],
   "source": [
    "file = open(\"glove.6B.50d.txt\",encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KnFk1-GQrOLi"
   },
   "outputs": [],
   "source": [
    "embedding_index = {}\n",
    "\n",
    "for line in file:\n",
    "    values = line.split()\n",
    "    \n",
    "    word = values[0]\n",
    "    word_embedding = np.array(values[1:],dtype='float')\n",
    "    embedding_index[word] = word_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RtWyL9iBtxZS"
   },
   "outputs": [],
   "source": [
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "GYphAPQttyiU",
    "outputId": "a186bc31-947d-45a0-8f5b-41cbf6fb8393"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.52042 , -0.8314  ,  0.49961 ,  1.2893  ,  0.1151  ,  0.057521,\n",
       "       -1.3753  , -0.97313 ,  0.18346 ,  0.47672 , -0.15112 ,  0.35532 ,\n",
       "        0.25912 , -0.77857 ,  0.52181 ,  0.47695 , -1.4251  ,  0.858   ,\n",
       "        0.59821 , -1.0903  ,  0.33574 , -0.60891 ,  0.41742 ,  0.21569 ,\n",
       "       -0.07417 , -0.5822  , -0.4502  ,  0.17253 ,  0.16448 , -0.38413 ,\n",
       "        2.3283  , -0.66682 , -0.58181 ,  0.74389 ,  0.095015, -0.47865 ,\n",
       "       -0.84591 ,  0.38704 ,  0.23693 , -1.5523  ,  0.64802 , -0.16521 ,\n",
       "       -1.4719  , -0.16224 ,  0.79857 ,  0.97391 ,  0.40027 , -0.21912 ,\n",
       "       -0.30938 ,  0.26581 ])"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_index['apple']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V-JlXgO2uJ6B"
   },
   "outputs": [],
   "source": [
    "def get_embedding_matrix():\n",
    "    EMBEDDING_DIM = 50\n",
    "    embedding_matrix = np.zeros((vocab_size, EMBEDDING_DIM))\n",
    "\n",
    "    for word, index in word_to_index.items():\n",
    "        embedding_vector = embedding_index.get(word)\n",
    "\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[index] = embedding_vector\n",
    "\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "PcmdI0KCvGfL",
    "outputId": "3cdd2eb3-cbc2-4a4c-e31e-1e5098cc5ac3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2647, 50)\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = get_embedding_matrix()\n",
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P48UHX3gvNoH"
   },
   "source": [
    "#### Define Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert feature vector of image to smaller vector\n",
    "\n",
    "#Output of ResNEt goes into following input layer \n",
    "inp_img_features = Input(shape=(2048,))\n",
    "#Apply a Dropout to the input received\n",
    "inp_img1 = Dropout(0.3)(inp_img_features)\n",
    "inp_img2 = Dense(256, activation=\"relu\")(inp_img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Layer dropout_3 was called with an input that isn't a symbolic tensor. Received type: <class 'keras.layers.embeddings.Embedding'>. Full input: [<keras.layers.embeddings.Embedding object at 0x640841850>]. All inputs to the layer should be tensors.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m                 \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_keras_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mis_keras_tensor\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    696\u001b[0m         raise ValueError('Unexpectedly found an instance of type `' +\n\u001b[0;32m--> 697\u001b[0;31m                          \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'`. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    698\u001b[0m                          'Expected a symbolic tensor instance.')\n",
      "\u001b[0;31mValueError\u001b[0m: Unexpectedly found an instance of type `<class 'keras.layers.embeddings.Embedding'>`. Expected a symbolic tensor instance.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-c60c3d2b19ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0minp_cap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0minp_cap1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_zero\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0minp_cap2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp_cap1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0minp_cap3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp_cap2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36msymbolic_fn_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_SYMBOLIC_SCOPE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    444\u001b[0m                 \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m                 \u001b[0;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                 \u001b[0;31m# Collect input shapes to build layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    314\u001b[0m                                  \u001b[0;34m'Received type: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m                                  \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'. Full input: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m                                  \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'. All inputs to the layer '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m                                  'should be tensors.')\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Layer dropout_3 was called with an input that isn't a symbolic tensor. Received type: <class 'keras.layers.embeddings.Embedding'>. Full input: [<keras.layers.embeddings.Embedding object at 0x640841850>]. All inputs to the layer should be tensors."
     ]
    }
   ],
   "source": [
    "#Now take Captions as input\n",
    "\n",
    "#Actual input size will be (batch_size x max_length_of_caption)\n",
    "#But here we specify only only for one example\n",
    "inp_cap = Input(shape=(max_len,))\n",
    "inp_cap1 = Embedding(input_dim=vocab_size, output_dim=50, mask_zero=True)\n",
    "inp_cap2 = Dropout(0.3)(inp_cap1)\n",
    "inp_cap3 = LSTM(256)(inp_cap2)\n",
    "# inp_cap3 captures esstenially the entire sentence that has been generated till now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "build.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
